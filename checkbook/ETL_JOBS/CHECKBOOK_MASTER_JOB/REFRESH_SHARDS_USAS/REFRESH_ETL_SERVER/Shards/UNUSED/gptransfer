#!/usr/bin/perl
#
# Copyright (C) 2007  Greenplum Inc.
# Florian Waas (flw@greenplum.com)
#
use Getopt::Long;
use Pod::Usage;
use strict;
use warnings;

=head1 NAME

B<gptransfer> - Greenplum Database Copy

=head1 SYNOPSIS

B<gptransfer> [-?] [-a] [-c] [-d] [-m] [-v] [-h host] [-p port] [-U user] [-l limit] [-s staging_schema] [-x] [-z] dbname

=head1 DESCRIPTION

gptransfer creates a SQL script which contains all information to setup a copy process to transfer a database between two separate GPDB instances. The script does not contain any data but rather external table defintions which allow parallel data transfer between the two instances.
The unit of data transfer is a database, not a complete system.

gptransfer writes the resulting SQL script to STDOUT.

=head1 OPTIONS

=over 6

=item -?|--help

Print usage information.

=item -a

Number of segments on the target system; if not provided an equal or greater number of segments is assumed. Only necessary if the database is to be copied to a smaller system.

=item -c

Include check information about sizes of tables; runs a query at the end to check if original and copied tables are of same size indicated by 'OK' or 'ERROR'.

=item -d

Include statements to drop all tables/schemas in the existing target database on the target system. Caveat: in case there is a large number of objects that needs to be dropped this can easily exceed the maximum number of locks per transaction and hence fail.

=item -h

Hostname of source system.

=item -l limit

This option is meant to test the plumbing but copies only a arbitarily small amount of data: every query is limited to <limit> number of rows.

=item -m

Print out debug information on STDERR which allows monitoring the script's progress.

=item -p

Master port of source system.

=item -s staging_schema

Name of auxiliary schema on the target system in which the external table definitions are created. Be default the name "stating" is used.

=item -U

User as which to connect to source system; must have super user privileges.

=item -v

The individual steps of copying the schema, setting up external tables, the data transfer etc. are 
stored as separate files prefixed gpx.N... This enables running/re-running individual steps of the resulting script.

=item -x

Be default gptransfer creates external tables using the 'ON SEGMENT <N>' syntax. In case source and target system
reside on the same cluster collocating external tables with their data source is highly desirable. -x ensures
the external tables are collocated by specifying the hostname explicitly in the external table definition. 
However, this option works only if there is exactly one segment per hostname
(as listed in gp_configuration) on the source as well as the target system.

gptransfer performs a check on the source system and ignores the option if more than one segment resides on the same
logical host; it cannot perform this check on the target system though -- it is the user's responsibility to make
sure it is safe to use this option. 

In case there are more segments per hostname, an incorrect amount of data is transferred, in case the target system
is not running on a sub/super-set of the hosts of the source system, the data transfer fails.

Using -c to check the number of rows transferred mitigates the risk.

=item -z

Include clean-up, e.g. dropping the staging schema, at the end of the script.

=head1 EXAMPLE

A typical usage of gptransfer looks like this. On source system

% gptransfer -p 5432 -m -c > copydb.sql

Then replay on target system with

% psql -p 9876 -f copydb.sql

=cut

my $glob_id = "";

my $GPSD = "gpsd";
my $copyright = "Copyright (C) 2007  Greenplum Inc.";
my $psqlClient = "psql";
my $pgdump = "pg_dump";
my $pgdumpall = "pg_dumpall";
my $commentPrefix = "-- ";
my $stagingSchema = "staging";
my $testLimit = 0;
my $sysnslist ="('pg_toast', 'pg_bitmapindex', 'pg_temp_1', ".
    "'pg_catalog', 'information_schema')";

my $singleFileMode = 0;
my $singleFileCnt = 1;

my $selectDateTime = "SELECT current_date, current_time; \n";

my $onhost = 0;
my $zap = 0;
my $drop = "";
my $debug = 0;

my $targetSeg = 0;

my $check = 0;
my $checkTable = "table_sizes";

# connection variables set from options
my $user = "";
my $port = "";
my $host = "";

my $cmdLine = "";

my %psqlUm;
my %hosts;

# format text as SQL comment
#
sub comment
{
    my $text = shift;
    my @lines = split '\n', $text."\<";
    my $comment = join "\n".$commentPrefix, @lines;
    
    $comment =~ s/\<$//g;
    return $commentPrefix.$comment. "\n";
}


sub writeFile
{
    return unless $singleFileMode;

    my ($desc, @content) = @_;
    
    my $filename = sprintf("gpx.%02d.%s.sql", $singleFileCnt++, $desc);
    open(FP, "> $filename") or die;

    print FP  @content;

    close FP;
}

# extract all schemas from a given database using $pgdump
#
sub getSchema
{
    my $db = shift;

    print STDERR "[INFO] EXECUTING: $pgdumpall $host $port $user -s -r --gp-syntax $db\n" if $debug;

    my $pid = open(PGDUMPALL, "$pgdumpall $host $port $user $drop -s -r -g --gp-syntax |") or die;
    die unless defined($pid);
    my @schema = <PGDUMPALL>;
    close PGDUMPALL;

    print STDERR "[INFO] DONE.\n" if $debug;

    die "$GPSD: reading from $pgdump ($pid) failed.\n" unless @schema;

    my $create = "";
    $create = "-C" unless $drop;
    push @schema, "\\connect $db\n" if $drop;

    print STDERR "[INFO] EXECUTING: $pgdump $host $port $user $drop -C -s --gp-syntax $db " if $debug;
    $pid = open(PGDUMP, "$pgdump $host $port $user $drop $create -s --gp-syntax $db |") or die;
    die unless defined($pid);
    push @schema, <PGDUMP>;
    close PGDUMP;

    push @schema, &comment("default DB");
    push @schema, "\\connect $db\n";

    push @schema, &comment("staging schema");
    push @schema, "DROP SCHEMA $stagingSchema  CASCADE;\n" if $drop;
    push @schema, "CREATE SCHEMA $stagingSchema;\n";

    print STDERR "[INFO] DONE.\n" if $debug;

    push @schema, $selectDateTime;
    writeFile("schema", @schema);

    return @schema;
}

# simple SQL executor using psql
# not using DBI as it doesn't come with the standard distribution
#
sub executeSQL
{
    my $db = shift;
    my $stmt = shift;

    print STDERR "[INFO] EXECUTING: $psqlClient $host $port $user $db -c \"$stmt\"\n" if $debug;

    my $pid = open(PSQL, "$psqlClient $host $port $user $db -c \"$stmt\" |") or die;
    die unless defined($pid);
    my @result = <PSQL>;
    close PSQL;

    my $len = $#result;
    @result = splice(@result, 0, $len - 1); 

    die "$GPSD: reading from $psqlClient ($pid) failed.\n" unless @result;

    print STDERR "[INFO] DONE.\n" if $debug;

    return @result;
}

# get server-side date,time,version
#
sub getDateTimeVersion
{
    my $db = shift;
    return 
	(&executeSQL($db, "SELECT current_date, current_time, version()"))[2]; 
}

# strip off leading and trailing blanks
#
sub mstrip
{
    $_ = shift @_;
    s|^\s*||;
    s|\s*$||;
    return $_;
}

# basic escaping of special chars
#
sub escValue
{
    $_ = shift;
    s|'|''|g;
    s|\\"|\\\\"|g;
    return $_;
}

# break up a row as it is returned from psql
# use the +'s in the formatting to decide on the width of the fields
#
sub splituprow
{
    my $line = shift;
    my $data = shift;
    
    #print "$line$data";

    my @parts = split '\+', $line;

    my $pos = 0;
    my @res = ();
    foreach my $part (@parts)
    {
	my $len = length($part);
	push @res, &mstrip(substr($data, $pos, $len));
	$pos += $len + 1;
    }
    return @res;
}


sub getPsqlUm
{
    my $db = shift;

    # get primary segments
    my $qry = "SELECT hostname, port FROM gp_configuration WHERE content <> -1 AND isprimary = 't'";

    my ($header, $line, @segments) = &executeSQL($db, $qry);

    my $cnt = 0;
    foreach my $seg (@segments)
    {
#	print $seg;
	my ($hostname, $port) = &splituprow($line, $seg);
	$hosts{$cnt} = $hostname;

	# if onhost option is set, let caller take care of getting us on the right host
	$hostname = "127.0.0.1" if $onhost;

	$psqlUm{$cnt} = "PGOPTIONS=\"-c gp_session_role=utility\" psql -h $hostname -p $port $user $db";
	$cnt++;
    }
    return $cnt;
}

sub getSequences
{
    my $db = shift;
    
    my $qry = 
	"SELECT pgn.nspname, pgc.relname FROM pg_class pgc, pg_namespace pgn ".
	"WHERE pgc.relkind = 'S' AND pgc.relnamespace=pgn.oid;";

    my @res;
    push @res, &comment("\nfix up sequences\n");

    my ($header, $line, @seqs) = &executeSQL($db, $qry);
    foreach my $seq (@seqs)
    {
	my ($schema, $seqname) = &splituprow($line, $seq);
	my $seqqry="SELECT last_value FROM $schema.$seqname;";

	my ($sheader, $sline, $sdata) = &executeSQL($db, $seqqry);
	my ($last) = &splituprow($sline, $sdata);

	my $next = $last + 1;
	push @res,
	"ALTER SEQUENCE $schema.$seqname RESTART WITH $next;\n";
    }

    writeFile("sequences", @res);
    return @res;
}

sub getTables
{
    my $db = shift;
    my $qry = "select schemaname, tablename from pg_tables where schemaname not like 'pg;_%' escape ';' and schemaname not in ('information_schema')";
    my ($header, $line, @tablespecs) = &executeSQL($db, $qry);

    my @tabspecs;
    foreach my $tabspec (@tablespecs)
    {
	my ($schemaname, $tabname) = &splituprow($line, $tabspec);
	push @tabspecs, "$schemaname.$tabname";
    }
    return @tabspecs;
}


sub getColumns
{
    my ($db, $table) = @_;
    
    my $qry = "select attname,typname from pg_attribute, pg_type pgt where attrelid = cast ('$table'::regclass as int) and attnum > 0 and atttypid = pgt.oid order by attnum";

    my ($header, $line, @columns) = &executeSQL($db, $qry);
    
    my @colspecs;
    foreach my $colspec (@columns)
    {
	my ($colname, $coltype) = &splituprow($line, $colspec);
	push @colspecs, "$colname $coltype";
    }
    return @colspecs;
}

sub segTabName
{
    my ($tabname, $seg) = @_;

    # eliminate '.'
    $tabname=~s|\.|\_|g;

    return "$stagingSchema.$tabname"."__".$seg unless $seg == -1;
    return "$stagingSchema.$tabname";
}

sub selectFromTab
{
    my $tab = shift;

    return "(select * from $tab limit $testLimit)" unless $testLimit == 0;
    return $tab;
}

sub createView
{
    my ($db, $tab) = @_;

    my @segs = keys %psqlUm;

    my @segtabs;
    my @segselects;

    push @segtabs, &comment("\nTABLE: $tab\n");
    push @segtabs, "begin;\n";

    my @cols = &getColumns($db, $tab);
    my $coldef = join ', ', @cols;

    $targetSeg = $#segs + 1 unless $targetSeg;
    foreach my $seg (sort @segs)
    {
	my $tabname = &segTabName($tab, $seg);
	
	my $tabdef = "CREATE EXTERNAL WEB TABLE $tabname ( $coldef ) EXECUTE ".
	    "E'$psqlUm{$seg} -c \"copy ". &selectFromTab($tab)." to stdout ".
	    "csv\"' ";

	if ($onhost)
	{
	    $tabdef .= "ON HOST '$hosts{$seg}' ";
	}
	else
	{
	    $tabdef .= "ON SEGMENT ".$seg%$targetSeg." ";
	}
	
	$tabdef .= "FORMAT 'csv';\n" ;
	
	push @segtabs, $tabdef;

	my $segselect = "select * from $tabname";
	push @segselects, $segselect;
    }

    my $viewname = &segTabName($tab, -1);
    
    my $union = join " UNION ALL ", @segselects; 
    my $viewdef = "CREATE VIEW $viewname AS ($union);\n";

    push @segtabs, $viewdef;
    push @segtabs, "commit;\n";

    return @segtabs;
}

sub createStage
{
    my ($db, @tabs) = @_;

    my @res;
    push @res, &comment("\nstaging schema\n");

    # warn about multiple segments and turn off onhost option as necessary
    my ($hd, $ln, @vals) = &executeSQL($db, 
	"select distinct cnt from (select count(*) as cnt ".
	"from gp_configuration where content >= 0 and isprimary=true group by hostname) foo");
    my ($cnt) = &splituprow($ln, $vals[0]);
    
    if ($onhost && ($cnt != 1 || $#vals > 0))
    {
	printf STDERR "[WARN] Warning: ON HOST option -x disabled; multiple segments per hostname\n";
	$onhost = 0;
    }

    my $segs = &getPsqlUm($db);

    push @res, &comment("\nview definitions\n");
    foreach my $tab (@tabs)
    {
	push @res, &createView($db, $tab);
    }

    push @res, $selectDateTime;
    writeFile("external", @res);
    return @res;
}


sub mkInserts
{
    my @tabs = @_;
    my @res;
    push @res, &comment("\nTransfer Data\n");

    foreach my $tab (@tabs)
    {
	my $stmt = "INSERT INTO $tab SELECT * FROM ".&segTabName($tab, -1).";\n";
	push @res, $stmt;
    }

    push @res, $selectDateTime;

    writeFile("xfer", @res);
    return @res;
}


sub initCheck
{
    my @tabs = @_;
    my @res;

    return unless $check;

    push @res, &comment("\nsetup check table\n");

    my $ct = "$stagingSchema.$checkTable";
    push @res, "CREATE TABLE $ct (tablename varchar, original bigint, copied bigint) distributed by (tablename);\n";
    foreach my $tab (@tabs)
    {
	push @res, "INSERT INTO $ct VALUES ('$tab', NULL, NULL );\n";
    }

    push @res, $selectDateTime;

    writeFile("initchecks", @res);
    return @res;
}


sub checkOrigTabs
{
    my ($db, @tabs) = @_;
    my @res;

    return unless $check;

    push @res, &comment("\ncheck orig sizes\n");

    foreach my $tab (@tabs)
    {
	my $stmt = "SELECT COUNT(*) FROM ".&selectFromTab($tab). " AS FOO";
	my ($header, $line, $result) = &executeSQL($db, $stmt);

	my ($count) = &splituprow($line, $result);

	push @res, "UPDATE $stagingSchema.$checkTable SET original = $count where tablename = '$tab';\n";
    }

    push @res, $selectDateTime;

    writeFile("checkOrig", @res);
    return @res;
}


sub checkNewTabs
{
    my ($checkcol, @tabs) = @_;    
    
    return unless $check;

    my @res;
    push @res, &comment("\ncheck new sizes\n");

    foreach my $tab (@tabs)
    {
	my $stmt = "UPDATE $stagingSchema.$checkTable SET copied = (SELECT COUNT(*) FROM ".&selectFromTab($tab)." AS FOO) WHERE tablename = '$tab';\n";
	push @res, $stmt;
    }

    push @res,
    "select tablename, original, copied, ".
	"case when original-copied <> 0 then 'ERROR' else 'OK' end as check ".
	"from $stagingSchema.$checkTable;\n";

    push @res, $selectDateTime;

    writeFile("checkNew", @res);
    return @res;
}

sub zap
{
    return unless $zap;

    my @tabs = @_;
    my @res;

    push @res, &comment("\nzapping external tables\n");

    my @segs = keys %psqlUm;
    foreach my $tab (@tabs)
    {
	push @res, "begin;\n";

	my $view = &segTabName($tab, -1);
	push @res, "DROP VIEW $view;\n";

	foreach my $seg (@segs)
	{
	    my $tabname = &segTabName($tab, $seg);
	    push @res, "DROP EXTERNAL TABLE $tabname;\n"
	}

	push @res, "commit;\n";
    }

    push @res, &comment("\ndrop check table (if applicable) and staging schema\n");
    push @res, "DROP TABLE $stagingSchema.$checkTable; \n" if $check;
    push @res, "DROP SCHEMA $stagingSchema CASCADE;\n";
    
    push @res, $selectDateTime;

    writeFile("zap", @res);
    return @res;
}

# dumper routine
#
sub dumper
{
    my $db = shift;

    my $dateTimeVersion =
	"SELECT current_date, current_time, version()";
    my ($header, $line, $row, @rem) = &executeSQL($db, $dateTimeVersion);
    my ($date, $time, $version) = &splituprow($line, $row);
    
    my @output = ();

    push @output, 
    &comment(
	"\nGreenplum Database Copy\n".
	$copyright."\n\n".

	"Database: $db\n".
	"Date:     $date\n".
	"Time:     $time\n".
	"CmdLine:  $cmdLine\n".
	"Version:  $version\n");

#    my $segs = &getPsqlUm($db);
    my @tabs = &getTables($db);

    push @output, $selectDateTime;
    
    push @output, &getSchema($db);
    push @output, &getSequences($db);
    push @output, &initCheck(@tabs);
    push @output, &checkOrigTabs($db, @tabs);
    push @output, &createStage($db, @tabs);
    push @output, &mkInserts(@tabs);
    push @output, &checkNewTabs($db, @tabs);

    push @output, &zap(@tabs);
    push @output, &comment("\nGreenplum Database Copy complete\n");

    return @output;
}


# parse options
my $man =0;
$cmdLine = join " ", @ARGV;

GetOptions
    (
     'help|?' => \$man,
     "a:i" => \$targetSeg,
     "h:s" => \$host,
     "p:i" => \$port,
     "U:s" => \$user,
     "c" => \$check,
     "d" => \$drop,
     "m" => \$debug,
     "s:s" => \$stagingSchema,
     "l:i" => \$testLimit,
     "v" => \$singleFileMode,
     "z" => \$zap,
     "x" => \$onhost
    )
    || 
    pod2usage(-msg => $glob_id, -verbose => 2);

$host = "-h $host" if "$host";
$user = "-U $user" if "$user";
$port = "-p $port" if "$port";
$drop = "-c" if $drop;

# display man page
pod2usage(-msg => $glob_id, -verbose => 2) if $man || !defined($ARGV[0]);

# call actual dumper
print &dumper($ARGV[0]);
